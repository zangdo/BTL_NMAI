_wandb:
    value:
        cli_version: 0.21.4
        e:
            b7pp7hl8qb5gdhh2io9meplermib04y1:
                args:
                    - num_envs=1024
                    - device=cuda
                    - epochs=500
                    - wandb.mode=online
                codePath: scripts/train_InRL.py
                codePathLocal: scripts/train_InRL.py
                cpu_count: 8
                cpu_count_logical: 16
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "1964636102656"
                        used: "1869798883328"
                email: zangdo20052014@gmail.com
                executable: /home/huongtt/miniconda3/envs/gomoku/bin/python
                git:
                    commit: ca7b826b637e7b5eee7180843ccc3e99b7b1c8c6
                    remote: https://github.com/ngthtuvp2005/Gomoku.git
                gpu: NVIDIA RTX A6000
                gpu_count: 2
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 10752
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX A6000
                      uuid: GPU-59430f48-5bbb-6fa3-1e1c-39b0fd176c69
                    - architecture: Ampere
                      cudaCores: 10752
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX A6000
                      uuid: GPU-0cfe36fc-d9b3-83b6-0bb8-bcabf9bb8e3b
                host: rtxa6000
                memory:
                    total: "134708895744"
                os: Linux-6.8.0-84-generic-x86_64-with-glibc2.39
                program: /home/huongtt/Zang/gomoku_rl/scripts/train_InRL.py
                python: CPython 3.10.18
                root: /home/huongtt/Zang/gomoku_rl
                startedAt: "2025-10-18T12:13:03.028194Z"
                writerId: b7pp7hl8qb5gdhh2io9meplermib04y1
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 50
                - 105
            "2":
                - 1
                - 50
                - 105
            "3":
                - 14
            "4": 3.10.18
            "5": 0.21.4
            "12": 0.21.4
            "13": linux-x86_64
algo.average_gae:
    value: false
algo.batch_size:
    value: 4096
algo.clip_param:
    value: 0.2
algo.entropy_coef:
    value: 0.01
algo.gae_lambda:
    value: 0.95
algo.gamma:
    value: 0.99
algo.max_grad_norm:
    value: 0.5
algo.name:
    value: ppo
algo.normalize_advantage:
    value: true
algo.num_channels:
    value: 64
algo.num_residual_blocks:
    value: 4
algo.optimizer.kwargs.lr:
    value: 0.0001
algo.optimizer.name:
    value: adam
algo.ppo_epochs:
    value: 3
algo.share_network:
    value: true
augment:
    value: false
baseline.average_gae:
    value: false
baseline.batch_size:
    value: 4096
baseline.clip_param:
    value: 0.2
baseline.entropy_coef:
    value: 0.001
baseline.gae_lambda:
    value: 0.95
baseline.gamma:
    value: 0.99
baseline.max_grad_norm:
    value: 0.5
baseline.name:
    value: ppo
baseline.normalize_advantage:
    value: true
baseline.num_channels:
    value: 64
baseline.num_residual_blocks:
    value: 4
baseline.optimizer.kwargs.lr:
    value: 0.0003
baseline.optimizer.name:
    value: adam
baseline.ppo_epochs:
    value: 3
baseline.share_network:
    value: true
black_checkpoint:
    value: pretrained_models/15_15/ppo/0.pt
black_checkpoint1:
    value: pretrained_models/15_15/ppo/2.pt
board_size:
    value: 15
device:
    value: cuda
epochs:
    value: 500
num_envs:
    value: 1024
out_device:
    value: cpu
run_dir:
    value: null
save_interval:
    value: 300
seed:
    value: 0
steps:
    value: 128
wandb.group:
    value: 15_15_ppo_InRL
wandb.mode:
    value: online
wandb.project:
    value: gomoku_rl
white_checkpoint:
    value: pretrained_models/15_15/ppo/1.pt
white_checkpoint1:
    value: pretrained_models/15_15/ppo/3.pt
